Коллеги, сегодня мы разберём ключевые компоненты кластера **Apache Kafka** — системы, которая стала индустриальным стандартом для построения масштабируемых потоковых данных. Понимание её архитектуры критически важно для проектирования отказоустойчивых и производительных data-платформ.

## 1. Брокер (Broker)
**Что это:** Отдельный сервер (узел) в кластере Kafka.  
**Роль:**
- Приём, хранение и отдача сообщений
- Управление репликацией данных
- Обработка запросов от производителей и потребителей

**Ключевые моменты:**
- Минимальный продакшен-кластер содержит **3+ брокера**
- Каждый брокер идентифицируется уникальным ID
- Автоматически обнаруживает других участников кластера

## 2. Zookeeper
**Историческая роль:**
- Координация кластера (до версии 2.8)
- Хранение метаданных:
    - Список брокеров
    - Конфигурация топиков
    - ACL и квоты
- Выбор контроллера (лидера кластера)

**Важно:** С появлением **KRaft mode** (Kafka Raft Metadata) Kafka постепенно уходит от зависимости от Zookeeper, что упрощает архитектуру и повышает стабильность.

## 3. Топики (Topics) и Партиции (Partitions)
**Топик:** Логический поток сообщений (аналог "таблицы" в БД)

**Партиции:**
- Механизм горизонтального масштабирования
- Каждая партиция — упорядоченная, неизменяемая последовательность
- Сообщения в партиции имеют уникальный **offset**
- Параллельная обработка: разные потребители могут читать из разных партиций

```
Пример: 
topic "orders" → partition_0, partition_1, partition_2
```

## 4. Репликация и Отказоустойчивость
**Replication Factor (RF):** Количество копий каждой партиции
- **Лидер (Leader):** Обрабатывает все read/write операции
- **Фолловеры (Followers):** Реплицируют данные с лидера

**Механизм гарантий:**
- **ISR (In-Sync Replicas):** Реплики, синхронизированные с лидером
- Контроллер отслеживает "лаги" репликации
- При падении лидера новая реплика выбирается из ISR

## 5. Producer & Consumer
**Producer:**
- Публикует сообщения в топики
- Может указывать ключ для детерминированного партиционирования
- Поддерживает различные уровни подтверждения (acks=0/1/all)

**Consumer:**
- Читает сообщения из топиков
- Работает в составе **Consumer Group**
- Каждая партиция обрабатывается только одним потребителем в группе
- Коммитит offsets для отслеживания прогресса

## 6. Consumer Groups
**Принцип:** "Каждое сообщение — одному потребителю в группе"
- Группа подписывается на один или несколько топиков
- Kafka автоматически распределяет партиции между потребителями
- При добавлении/удалении потребителей происходит **rebalance**

## 7. Контроллер (Controller)
**Роль:** "Мозг" кластера
- Специальный брокер, избранный через Zookeeper/KRaft
- Управляет жизненным циклом партиций
- Мониторит статус брокеров
- Инициирует ребалансировку при изменениях

## 8. KRaft (Kafka Raft Metadata)
**Современная архитектура:**
- Замена Zookeeper (production-ready с версии 3.3+)
- Использует Raft-консенсус для метаданных
- **Преимущества:**
    - Проще эксплуатация (1 система вместо 2)
    - Быстрее recovery и масштабирование
    - Упрощённая безопасность

## Практические рекомендации:

**Производительность:**
- Количество партиций = максимальная параллельность
- Мониторинг lag репликации
- Настройка retention policies

**Надёжность:**
- RF ≥ 3 в продакшене
- min.insync.replicas = 2
- Размещение брокеров в разных AZ

**Безопасность:**
- SSL/TLS для передачи данных
- SASL для аутентификации
- RBAC через ACL

Кластер Kafka — это сложный, но чрезвычайно мощный механизм. Глубокое понимание его компонентов позволяет строить системы, способные обрабатывать миллионы событий в секунду с гарантированной доставкой.

Для каких use cases в ваших проектах рассматриваете Kafka?